# âœ… Supabase Storage Setup Complete - Hindi Guide

## ğŸ‰ à¤•à¥à¤¯à¤¾ à¤¹à¥‹ à¤šà¥à¤•à¤¾ à¤¹à¥ˆ?

à¤†à¤ªà¤•à¤¾ AIMS application **à¤ªà¤¹à¤²à¥‡ à¤¸à¥‡ à¤¹à¥€ Supabase Storage use à¤•à¤° à¤°à¤¹à¤¾ à¤¹à¥ˆ**! AWS S3 à¤•à¤­à¥€ integrate à¤¨à¤¹à¥€à¤‚ à¤¥à¤¾à¥¤

---

## ğŸ“¦ Required Storage Buckets

à¤†à¤ªà¤•à¥‹ Supabase Dashboard à¤®à¥‡à¤‚ à¤¯à¥‡ buckets à¤¬à¤¨à¤¾à¤¨à¥‡ à¤¹à¥ˆà¤‚:

### 1. **patient-reports** (Primary Bucket)
- **Purpose:** Patient à¤•à¥€ .edf, .eeg, .bdf files store à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤
- **Privacy:** Private (RLS policies à¤•à¥‡ à¤¸à¤¾à¤¥)
- **Max File Size:** 50MB
- **File Structure:**
  ```
  patient-reports/
  â”œâ”€â”€ {clinic_id}/
  â”‚   â”œâ”€â”€ {patient_id}/
  â”‚   â”‚   â”œâ”€â”€ 2025-01-15T10-30-00_sample.edf
  â”‚   â”‚   â”œâ”€â”€ 2025-01-16T14-20-00_test.eeg
  â”‚   â”‚   â””â”€â”€ ...
  ```

### 2. **eeg-files** (Raw EEG Storage)
- **Purpose:** Raw EEG data files
- **Privacy:** Private
- **Max File Size:** 50MB
- **File Structure:**
  ```
  eeg-files/
  â”œâ”€â”€ {clinic_id}/
  â”‚   â”œâ”€â”€ {patient_id}/
  â”‚   â”‚   â”œâ”€â”€ {session_id}_raw.edf
  â”‚   â”‚   â””â”€â”€ ...
  ```

### 3. **reports** (Generated Reports)
- **Purpose:** AI-generated PDF/CSV/HTML reports
- **Privacy:** Private
- **Max File Size:** 50MB
- **File Structure:**
  ```
  reports/
  â”œâ”€â”€ {clinic_id}/
  â”‚   â”œâ”€â”€ {patient_id}/
  â”‚   â”‚   â”œâ”€â”€ analysis_report.pdf
  â”‚   â”‚   â”œâ”€â”€ care_plan.pdf
  â”‚   â”‚   â””â”€â”€ ...
  ```

### 4. **clinic-logos** (Branding)
- **Purpose:** Clinic logos à¤”à¤° branding images
- **Privacy:** Public (logos à¤•à¥‹ display à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤)
- **Max File Size:** 5MB
- **File Structure:**
  ```
  clinic-logos/
  â”œâ”€â”€ {clinic_id}/
  â”‚   â”œâ”€â”€ logo.png
  â”‚   â””â”€â”€ branding.jpg
  ```

---

## ğŸš€ Step-by-Step Setup Instructions

### Step 1: Supabase Dashboard à¤–à¥‹à¤²à¥‡à¤‚

1. **Browser à¤®à¥‡à¤‚ à¤œà¤¾à¤à¤‚:** https://supabase.com
2. **Login à¤•à¤°à¥‡à¤‚** à¤…à¤ªà¤¨à¥‡ account à¤¸à¥‡
3. **AIMS project select à¤•à¤°à¥‡à¤‚**

### Step 2: Storage Buckets à¤¬à¤¨à¤¾à¤à¤‚

1. **Left sidebar à¤®à¥‡à¤‚ "Storage" à¤ªà¤° click à¤•à¤°à¥‡à¤‚**
2. **"Create a new bucket" button à¤ªà¤° click à¤•à¤°à¥‡à¤‚**

#### Bucket 1 à¤¬à¤¨à¤¾à¤à¤‚:
```
Name: patient-reports
Public: âŒ NO (Private à¤°à¤–à¥‡à¤‚)
File size limit: 52428800 (50MB)
Allowed MIME types: (Leave empty)
```
**"Create bucket" button à¤ªà¤° click à¤•à¤°à¥‡à¤‚**

#### Bucket 2 à¤¬à¤¨à¤¾à¤à¤‚:
```
Name: eeg-files
Public: âŒ NO (Private)
File size limit: 52428800 (50MB)
```

#### Bucket 3 à¤¬à¤¨à¤¾à¤à¤‚:
```
Name: reports
Public: âŒ NO (Private)
File size limit: 52428800 (50MB)
```

#### Bucket 4 à¤¬à¤¨à¤¾à¤à¤‚:
```
Name: clinic-logos
Public: âœ… YES (Public - logos display à¤•à¥‡ à¤²à¤¿à¤)
File size limit: 5242880 (5MB)
```

### Step 3: Storage Policies Setup à¤•à¤°à¥‡à¤‚

1. **Supabase Dashboard à¤®à¥‡à¤‚ "SQL Editor" à¤–à¥‹à¤²à¥‡à¤‚**
2. **"New query" button à¤ªà¤° click à¤•à¤°à¥‡à¤‚**
3. **à¤¨à¥€à¤šà¥‡ à¤¦à¥€ à¤—à¤ˆ SQL file à¤•à¥‹ copy à¤•à¤°à¥‡à¤‚ à¤”à¤° paste à¤•à¤°à¥‡à¤‚:**

ğŸ“„ File location: `D:\AIMS\supabase\storage-policies.sql`

4. **"Run" button à¤ªà¤° click à¤•à¤°à¥‡à¤‚**

à¤¯à¤¹ SQL file automatically à¤¸à¤­à¥€ security policies create à¤•à¤° à¤¦à¥‡à¤—à¥€:
- âœ… Clinics à¤…à¤ªà¤¨à¥‡ patients à¤•à¥€ files upload à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚
- âœ… Clinics à¤¸à¤¿à¤°à¥à¤« à¤…à¤ªà¤¨à¥‡ patients à¤•à¥€ files à¤¦à¥‡à¤– à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚
- âœ… Super admin à¤¸à¤­à¥€ files access à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚
- âœ… Unauthorized access blocked à¤¹à¥ˆ

### Step 4: Verify Setup

SQL Editor à¤®à¥‡à¤‚ à¤¯à¥‡ queries run à¤•à¤°à¥‡à¤‚:

```sql
-- Check if all buckets exist
SELECT * FROM storage.buckets;
```

**Expected Output:** à¤†à¤ªà¤•à¥‹ 4 buckets à¤¦à¤¿à¤–à¤¨à¥‡ à¤šà¤¾à¤¹à¤¿à¤:
- patient-reports
- eeg-files
- reports
- clinic-logos

```sql
-- Check policies
SELECT * FROM pg_policies
WHERE tablename = 'objects'
AND schemaname = 'storage';
```

**Expected Output:** Multiple policies à¤¦à¤¿à¤–à¤¨à¥‡ à¤šà¤¾à¤¹à¤¿à¤ (upload, view, delete permissions)

---

## ğŸ”§ Code Changes Done

### 1. **storageService.js Updated** âœ…

**Location:** `D:\AIMS\src\services\storageService.js`

**Changes:**
- âœ… Files à¤…à¤¬ clinic à¤”à¤° patient à¤•à¥‡ according organize à¤¹à¥‹à¤¤à¥€ à¤¹à¥ˆà¤‚
- âœ… File path structure: `{clinic_id}/{patient_id}/{filename}`
- âœ… New methods added:
  - `listClinicFiles(clinicId)` - Clinic à¤•à¥€ à¤¸à¤­à¥€ files list à¤•à¤°à¥‡à¤‚
  - `listPatientFiles(clinicId, patientId)` - Patient à¤•à¥€ files list à¤•à¤°à¥‡à¤‚

**Example Usage:**
```javascript
import StorageService from './services/storageService';

// Upload file with clinic and patient info
const result = await StorageService.uploadFile(
  file,
  'sample.edf',
  {
    clinicId: 'clinic-123',
    patientId: 'patient-456'
  }
);
// File saved at: patient-reports/clinic-123/patient-456/2025-01-15T10-30-00_sample.edf

// List all files for a patient
const files = await StorageService.listPatientFiles('clinic-123', 'patient-456');
```

### 2. **.env.example Cleaned** âœ…

**Location:** `D:\AIMS\.env.example`

**Changes:**
- âŒ AWS credentials references removed
- âœ… Only Supabase configuration remains

---

## ğŸ“± How Upload Works Now

### Upload Flow:

```
User uploads .edf file
        â†“
Component passes file with metadata:
  - clinicId
  - patientId
        â†“
storageService.uploadFile()
  - Validates file (.edf, .eeg, .bdf only)
  - Creates path: {clinicId}/{patientId}/{timestamp}_{filename}
  - Uploads to Supabase Storage bucket
        â†“
File saved at:
patient-reports/clinic-123/patient-456/2025-01-15T10-30-00_sample.edf
        â†“
RLS Policy checks:
  - Is user authenticated?
  - Does clinic_id match user's clinic?
  - âœ… Allow / âŒ Deny
```

### Security:

âœ… **Each clinic can only:**
- Upload files to their own folder
- View files in their own folder
- Delete files in their own folder

âŒ **Clinics CANNOT:**
- Access other clinics' files
- View files outside their folder
- Delete other clinics' data

âœ… **Super Admin can:**
- Access all files
- View all clinics' data
- Manage all uploads

---

## ğŸ§ª Testing Upload

### Test à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤:

1. **Application run à¤•à¤°à¥‡à¤‚:**
   ```bash
   npm run dev
   ```

2. **Login à¤•à¤°à¥‡à¤‚** as clinic user

3. **Patient dashboard à¤–à¥‹à¤²à¥‡à¤‚**

4. **"Upload Report" button à¤ªà¤° click à¤•à¤°à¥‡à¤‚**

5. **Sample .edf file upload à¤•à¤°à¥‡à¤‚**

6. **Supabase Dashboard à¤®à¥‡à¤‚ verify à¤•à¤°à¥‡à¤‚:**
   - Storage â†’ patient-reports bucket à¤–à¥‹à¤²à¥‡à¤‚
   - à¤†à¤ªà¤•à¥‹ folder structure à¤¦à¤¿à¤–à¥‡à¤—à¤¾:
     ```
     patient-reports/
     â””â”€â”€ {your-clinic-id}/
         â””â”€â”€ {patient-id}/
             â””â”€â”€ {timestamp}_filename.edf
     ```

---

## ğŸ” Debug Commands

### Check Upload Logs:

Browser Console à¤®à¥‡à¤‚ (F12) à¤¦à¥‡à¤–à¥‡à¤‚:
```
Uploading file to Supabase Storage: sample.edf
File uploaded successfully: clinic-123/patient-456/2025-01-15T10-30-00_sample.edf
```

### Check Storage in Supabase:

SQL Editor à¤®à¥‡à¤‚ run à¤•à¤°à¥‡à¤‚:
```sql
-- List all uploaded files
SELECT
  name,
  bucket_id,
  created_at,
  metadata
FROM storage.objects
WHERE bucket_id = 'patient-reports'
ORDER BY created_at DESC
LIMIT 10;
```

### Check File Permissions:

```sql
-- Check if current user can access files
SELECT
  o.*,
  p.role
FROM storage.objects o
JOIN profiles p ON p.id = auth.uid()
WHERE o.bucket_id = 'patient-reports'
AND o.name LIKE '%' || auth.uid()::text || '%';
```

---

## âŒ Common Issues & Solutions

### Issue 1: "Bucket does not exist"

**Solution:**
1. Supabase Dashboard â†’ Storage
2. Create bucket manually with exact name
3. Refresh application

### Issue 2: "Upload failed: permission denied"

**Solution:**
1. Supabase Dashboard â†’ SQL Editor
2. Run `storage-policies.sql` again
3. Verify policies exist:
   ```sql
   SELECT * FROM pg_policies
   WHERE tablename = 'objects';
   ```

### Issue 3: "File size exceeds limit"

**Solution:**
- Maximum file size à¤¹à¥ˆ 50MB
- Large files à¤•à¥‹ compress à¤•à¤°à¥‡à¤‚ à¤¯à¤¾
- Bucket settings à¤®à¥‡à¤‚ file size limit à¤¬à¤¢à¤¼à¤¾à¤à¤‚

### Issue 4: "Invalid file format"

**Solution:**
- Allowed formats: `.edf`, `.eeg`, `.bdf`
- File extension check case-sensitive à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆ
- File rename à¤•à¤°à¥‡à¤‚ proper extension à¤•à¥‡ à¤¸à¤¾à¤¥

---

## ğŸ“Š File Organization Examples

### Example 1: Multiple Patients, One Clinic

```
patient-reports/
â”œâ”€â”€ clinic-abc-123/
â”‚   â”œâ”€â”€ patient-001/
â”‚   â”‚   â”œâ”€â”€ 2025-01-15T10-00-00_baseline.edf
â”‚   â”‚   â””â”€â”€ 2025-01-20T11-30-00_followup.edf
â”‚   â”œâ”€â”€ patient-002/
â”‚   â”‚   â”œâ”€â”€ 2025-01-16T09-15-00_initial.edf
â”‚   â”‚   â””â”€â”€ 2025-01-18T14-00-00_assessment.edf
â”‚   â””â”€â”€ patient-003/
â”‚       â””â”€â”€ 2025-01-17T16-45-00_screening.edf
```

### Example 2: Multiple Clinics

```
patient-reports/
â”œâ”€â”€ clinic-abc-123/
â”‚   â””â”€â”€ patient-001/
â”‚       â””â”€â”€ 2025-01-15T10-00-00_baseline.edf
â”œâ”€â”€ clinic-xyz-456/
â”‚   â””â”€â”€ patient-001/  (Different patient, same ID but different clinic)
â”‚       â””â”€â”€ 2025-01-15T11-00-00_baseline.edf
â””â”€â”€ clinic-def-789/
    â””â”€â”€ patient-002/
        â””â”€â”€ 2025-01-16T12-00-00_initial.edf
```

**Note:** à¤¹à¤° clinic à¤•à¤¾ à¤…à¤ªà¤¨à¤¾ isolated folder à¤¹à¥ˆ, à¤‡à¤¸à¤²à¤¿à¤:
- âœ… Patient IDs different clinics à¤®à¥‡à¤‚ repeat à¤¹à¥‹ à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚
- âœ… à¤•à¥‹à¤ˆ data mixing à¤¨à¤¹à¥€à¤‚ à¤¹à¥‹à¤—à¥€
- âœ… Privacy maintained à¤°à¤¹à¥‡à¤—à¥€

---

## ğŸ¯ Next Steps

### âœ… Already Done:
- [x] Storage service Supabase à¤•à¥‡ à¤²à¤¿à¤ configured à¤¹à¥ˆ
- [x] File upload clinic/patient structure à¤•à¥‡ à¤¸à¤¾à¤¥ organize à¤¹à¥ˆ
- [x] AWS references removed from code
- [x] Security policies ready (SQL file à¤®à¥‡à¤‚)

### ğŸš€ You Need to Do:

1. **Supabase Dashboard à¤®à¥‡à¤‚ 4 buckets à¤¬à¤¨à¤¾à¤à¤‚** (10 minutes)
2. **SQL policies run à¤•à¤°à¥‡à¤‚** (2 minutes)
3. **Test upload à¤•à¤°à¥‡à¤‚** (5 minutes)
4. **Verify files bucket à¤®à¥‡à¤‚ à¤¦à¤¿à¤– à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚** (2 minutes)

**Total Time:** ~20 minutes

---

## ğŸ“ Support

### If Upload Fails:

1. **Browser Console check à¤•à¤°à¥‡à¤‚** (F12 â†’ Console tab)
2. **Supabase Dashboard logs à¤¦à¥‡à¤–à¥‡à¤‚** (Logs & Analytics)
3. **Verify bucket permissions:**
   ```sql
   SELECT * FROM pg_policies
   WHERE tablename = 'objects'
   AND schemaname = 'storage';
   ```

### If Files Not Visible:

1. **Check RLS policies applied à¤¹à¥ˆà¤‚ à¤¯à¤¾ à¤¨à¤¹à¥€à¤‚**
2. **Verify clinic_id correct à¤¹à¥ˆ:**
   ```javascript
   console.log('Current user:', supabase.auth.getUser());
   ```
3. **Check file path structure:**
   ```sql
   SELECT name FROM storage.objects
   WHERE bucket_id = 'patient-reports';
   ```

---

## ğŸ“ Important Notes

1. **Bucket Names Case-Sensitive Hà¥ˆà¤‚:**
   - âœ… `patient-reports` (correct)
   - âŒ `Patient-Reports` (wrong)
   - âŒ `patient_reports` (wrong)

2. **File Path Structure Important à¤¹à¥ˆ:**
   - âœ… `{clinic_id}/{patient_id}/{file}` (correct)
   - âŒ `{patient_id}/{file}` (missing clinic_id)
   - âŒ `reports/{clinic_id}/{file}` (extra folder)

3. **Metadata Always Pass à¤•à¤°à¥‡à¤‚:**
   ```javascript
   // âœ… Correct
   StorageService.uploadFile(file, 'test.edf', {
     clinicId: 'clinic-123',
     patientId: 'patient-456'
   });

   // âŒ Wrong (files 'unknown-clinic' folder à¤®à¥‡à¤‚ à¤œà¤¾à¤à¤‚à¤—à¥€)
   StorageService.uploadFile(file, 'test.edf');
   ```

4. **RLS Policies Essential à¤¹à¥ˆà¤‚:**
   - Policies à¤•à¥‡ à¤¬à¤¿à¤¨à¤¾: âŒ Permission denied errors
   - Policies à¤•à¥‡ à¤¸à¤¾à¤¥: âœ… Secure file access

---

## âœ… Checklist

Before going live, verify:

- [ ] All 4 buckets created in Supabase Dashboard
- [ ] Storage policies SQL script executed successfully
- [ ] Test upload successful
- [ ] Files visible in correct folder structure
- [ ] Clinic can access only their files
- [ ] Super admin can access all files
- [ ] File download working
- [ ] File delete working
- [ ] Error handling tested

---

## ğŸ‰ Summary

**What Changed:**
1. âœ… Storage service à¤…à¤¬ clinic/patient à¤•à¥‡ according files organize à¤•à¤°à¤¤à¥€ à¤¹à¥ˆ
2. âœ… AWS references remove à¤¹à¥‹ à¤—à¤
3. âœ… Security policies ready à¤¹à¥ˆà¤‚
4. âœ… Upload workflow complete à¤¹à¥ˆ

**What You Need to Do:**
1. ğŸ¯ Supabase Dashboard à¤®à¥‡à¤‚ buckets à¤¬à¤¨à¤¾à¤à¤‚
2. ğŸ¯ SQL policies run à¤•à¤°à¥‡à¤‚
3. ğŸ¯ Test upload à¤•à¤°à¥‡à¤‚

**Result:**
- ğŸ“ Files organized by clinic and patient
- ğŸ”’ Secure access with RLS policies
- âš¡ Fast uploads with Supabase Storage
- ğŸ’° No AWS costs!

---

à¤¬à¤¸ à¤‡à¤¤à¤¨à¤¾ à¤¹à¥€! à¤…à¤¬ à¤†à¤ª Supabase Storage use à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ ready à¤¹à¥ˆà¤‚! ğŸš€

Questions? Check the SQL policies file à¤¯à¤¾ console logs à¤¦à¥‡à¤–à¥‡à¤‚ for debugging.
